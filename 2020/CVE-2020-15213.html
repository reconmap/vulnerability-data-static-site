<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		
		<title>CVE-2020-15213 - Vulnerability Data</title>
		
		<link rel="shortcut icon" type="image/png" href="/favicon.ico" />
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css">
		  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
		<script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/js/materialize.min.js"></script>
		<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-175514417-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-175514417-4');
</script>

	</head>
<body>
	<div class="container">
	

  <nav>
    <div class="nav-wrapper">
      <div class="col s12">
        <a href="https://www.vulnerabilitydata.com" class="breadcrumb">Vulnerability Data</a>
        <a href="/2020" class="breadcrumb">2020</a>
        <a href="#" class="breadcrumb">CVE-2020-15213</a>
      </div>
    </div>
  </nav>

<h2>Vulnerability Data</h2>
<h1>CVE-2020-15213</h1>
<p>In TensorFlow Lite before versions 2.2.1 and 2.3.1, models using segment sum can trigger a denial of service by causing an out of memory allocation in the implementation of segment sum. Since code uses the last element of the tensor holding them to determine the dimensionality of output tensor, attackers can use a very large value to trigger a large allocation. The issue is patched in commit 204945b19e44b57906c9344c0d00120eeeae178a and is released in TensorFlow versions 2.2.1, or 2.3.1. A potential workaround would be to add a custom `Verifier` to limit the maximum value in the segment ids tensor. This only handles the case when the segment ids are stored statically in the model, but a similar validation could be done if the segment ids are generated at runtime, between inference steps. However, if the segment ids are generated as outputs of a tensor during inference steps, then there are no possible workaround and users are advised to upgrade to patched code.</p>

<dl>
	<dt>Published</dt>
	<dd>2020-09-25</dd>

	<dt>Modified</dt>
	<dd>2020-09-25</dd>
</dl>

<h3>References</h3>
<ul>
	<li><a href="https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hjmq-236j-8m87">CONFIRM:https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hjmq-236j-8m87</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/commit/204945b19e44b57906c9344c0d00120eeeae178a">MISC:https://github.com/tensorflow/tensorflow/commit/204945b19e44b57906c9344c0d00120eeeae178a</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/releases/tag/v2.3.1">MISC:https://github.com/tensorflow/tensorflow/releases/tag/v2.3.1</a></li>
</ul>

<footer>
	<p><a href="https://reconmap.org">Track security vulnerabilities</a> with <strong>Reconmap</strong>.</p>
</footer>


	</div>
</body>
</html>